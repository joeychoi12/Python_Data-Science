{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 49.1842, 기울기 a1 = 7.5270, 기울기 a2 = 7.8160, y절편 b = 80.5980\n",
      "Epoch: 100, RMSE = 1.8368, 기울기 a1 = 1.1306, 기울기 a2 = 2.1316, y절편 b = 78.5119\n",
      "Epoch: 200, RMSE = 1.8370, 기울기 a1 = 1.1879, 기울기 a2 = 2.1487, y절편 b = 78.1057\n",
      "Epoch: 300, RMSE = 1.8370, 기울기 a1 = 1.2122, 기울기 a2 = 2.1571, y절편 b = 77.9352\n",
      "Epoch: 400, RMSE = 1.8370, 기울기 a1 = 1.2226, 기울기 a2 = 2.1607, y절편 b = 77.8636\n",
      "Epoch: 500, RMSE = 1.8370, 기울기 a1 = 1.2269, 기울기 a2 = 2.1622, y절편 b = 77.8335\n",
      "Epoch: 600, RMSE = 1.8370, 기울기 a1 = 1.2288, 기울기 a2 = 2.1628, y절편 b = 77.8208\n",
      "Epoch: 700, RMSE = 1.8370, 기울기 a1 = 1.2295, 기울기 a2 = 2.1631, y절편 b = 77.8155\n",
      "Epoch: 800, RMSE = 1.8370, 기울기 a1 = 1.2299, 기울기 a2 = 2.1632, y절편 b = 77.8133\n",
      "Epoch: 900, RMSE = 1.8370, 기울기 a1 = 1.2300, 기울기 a2 = 2.1632, y절편 b = 77.8124\n",
      "Epoch: 1000, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8120\n",
      "Epoch: 1100, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8118\n",
      "Epoch: 1200, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1300, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1400, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1500, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1600, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1700, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1800, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 1900, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n",
      "Epoch: 2000, RMSE = 1.8370, 기울기 a1 = 1.2301, 기울기 a2 = 2.1633, y절편 b = 77.8117\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "#x1, x2, y의 데이터 값\n",
    "\n",
    "data = [[2,0,81], [4,4,93], [6,2,91], [8,3,97]]\n",
    "x1 = [x_row1[0] for x_row1 in data]\n",
    "x2 = [x_row2[1] for x_row2 in data] # 새로 추가 되는 값\n",
    "y_data = [y_row[2] for y_row in data] \n",
    "\n",
    "#기울기 a 와 y 절편 b의 값을 임의로 정한다. \n",
    "#단 기울기의 범위는 0~10 사이이며, y 절편은 0~100 사이에서 변하게 한다. \n",
    "\n",
    "a1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype = tf.float64,\n",
    "                                  seed = 0))\n",
    "a2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype = tf.float64,\n",
    "                                  seed = 0)) #새로 추가 되는 값\n",
    "b = tf.Variable(tf.random_uniform([1],0,100, dtype = tf.float64,\n",
    "                                 seed = 0))\n",
    "\n",
    "#새로운 방정식 \n",
    "y = a1 * x1 + a2 * x2 + b \n",
    "\n",
    "#텐서플로 RMSE 함수 \n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(y -y_data)))\n",
    "\n",
    "#학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "#RMSE 값을 최소로 하는 값 찾기 \n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "#학습이 진행되는 부분\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_decent)\n",
    "        if step % 100 == 0 : \n",
    "            print(\"Epoch: %.f, RMSE = %.04f, 기울기 a1 = %.4f, 기울기 a2 = %.4f, y절편 b = %.4f\" \n",
    "                 % (step,sess.run(rmse), sess.run(a1), sess.run(a2),sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "### 로지스틱 회귀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "data = [[2,0],[4,0],[6,0],[8,1],[10,1],[12,1],[14,1]]\n",
    "x_data = [x_row[0] for x_row in data]\n",
    "y_data = [y_row[1] for y_row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable_13:0' shape=(1,) dtype=float64_ref>,\n",
       " <tf.Variable 'Variable_14:0' shape=(1,) dtype=float64_ref>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a 와 b 값을 임의로 정함 \n",
    "a = tf.Variable(tf.random_normal([1], dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_normal([1], dtype = tf.float64, seed = 0))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시그모이드 함정식 from numpy\n",
    "y = 1/(1 + np.e**(-a * x_data + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오차 = -평균(y*logh + (1-y)log(1-h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Neg_2:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -tf.reduce_mean(np.array(y_data) * tf.log(y) + (1-np.array(y_data)) * tf.log(1-y))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "#loss 를 최소로 하는 값 찾기 \n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss = 4.4835, 기울기 a = 2.3946, y절편 = -0.8820\n",
      "Epoch: 6000, loss = 0.0152, 기울기 a = 2.9209, y절편 = 20.2966\n",
      "Epoch: 12000, loss = 0.0081, 기울기 a = 3.5636, y절편 = 24.8002\n",
      "Epoch: 18000, loss = 0.0055, 기울기 a = 3.9556, y절편 = 27.5458\n",
      "Epoch: 24000, loss = 0.0041, 기울기 a = 4.2380, y절편 = 29.5227\n",
      "Epoch: 30000, loss = 0.0033, 기울기 a = 4.4585, y절편 = 31.0672\n",
      "Epoch: 36000, loss = 0.0028, 기울기 a = 4.6395, y절편 = 32.3343\n",
      "Epoch: 42000, loss = 0.0024, 기울기 a = 4.7929, y절편 = 33.4084\n",
      "Epoch: 48000, loss = 0.0021, 기울기 a = 4.9261, y절편 = 34.3404\n",
      "Epoch: 54000, loss = 0.0019, 기울기 a = 5.0436, y절편 = 35.1634\n",
      "Epoch: 60000, loss = 0.0017, 기울기 a = 5.1489, y절편 = 35.9003\n"
     ]
    }
   ],
   "source": [
    "#학습 \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(60001):\n",
    "        sess.run(gradient_decent)\n",
    "        if i % 6000 == 0:\n",
    "            print(\"Epoch: %.f, loss = %.4f, 기울기 a = %.4f, y절편 = %.4f\" %\n",
    "                 (i, sess.run(loss), sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러 입력 값을 갖는 로지스틱 회귀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행할 때마다 같은 결과를 출력하기 위한 seed 값 설정\n",
    "seed = 0 \n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[2,3], [4,3],[6,4],[8,6],[10,7],[12,8],[14,9]])\n",
    "y_data = np.array([0,0,0,1,1,1,1]).reshape(7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder\n",
    "X = tf.placeholder(tf.float64, shape = [None, 2])\n",
    "Y = tf.placeholder(tf.float64, shape = [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기울기 a와 바이어스 b의 값을 임의로 정함 \n",
    "a = tf.Variable(tf.random_uniform([2,1], dtype = tf.float64))\n",
    "#[2,1]의미: 들어오는 값은 2개, 나가는 값은 1개 \n",
    "b = tf.Variable(tf.random_uniform([1], dtype = tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 시그모이드 함수의 방정식을 세움 \n",
    "y = tf.sigmoid(tf.matmul(X, a) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차를 구하는 함수 \n",
    "loss = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1-y))\n",
    "\n",
    "#학습률 값\n",
    "learning_rate = 0.1\n",
    "\n",
    "#오차를 최소로 하는 값 찾기 \n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=300, a1 =  0.9460, a2 = -0.8095, b=-2.0361, loss = 0.2925\n",
      "step=600, a1 =  0.9211, a2 = -0.4881, b=-3.5939, loss = 0.2068\n",
      "step=900, a1 =  0.8125, a2 = -0.1243, b=-4.7147, loss = 0.1598\n",
      "step=1200, a1 =  0.6942, a2 = 0.2099, b=-5.5957, loss = 0.1296\n",
      "step=1500, a1 =  0.5838, a2 = 0.5046, b=-6.3223, loss = 0.1086\n",
      "step=1800, a1 =  0.4853, a2 = 0.7623, b=-6.9408, loss = 0.0933\n",
      "step=2100, a1 =  0.3988, a2 = 0.9881, b=-7.4793, loss = 0.0816\n",
      "step=2400, a1 =  0.3229, a2 = 1.1872, b=-7.9563, loss = 0.0725\n",
      "step=2700, a1 =  0.2562, a2 = 1.3642, b=-8.3843, loss = 0.0652\n",
      "step=3000, a1 =  0.1973, a2 = 1.5226, b=-8.7725, loss = 0.0592\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.cast(y > 0.5, dtype = tf.float64)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float64))\n",
    "\n",
    "# 학습 \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3001): \n",
    "        a_,b_,loss_, _ = sess.run([a,b,loss,gradient_decent], feed_dict={X: x_data, Y: y_data})\n",
    "        if (i + 1) % 300 == 0: \n",
    "            print(\"step=%d, a1 =  %.4f, a2 = %.4f, b=%.4f, loss = %.4f\" % (i + 1, a_[0], a_[1], b_, loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 값 적용  활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=300, a1 =  0.9460, a2 = -0.8095, b=-2.0361, loss = 0.2925\n",
      "step=600, a1 =  0.9211, a2 = -0.4881, b=-3.5939, loss = 0.2068\n",
      "step=900, a1 =  0.8125, a2 = -0.1243, b=-4.7147, loss = 0.1598\n",
      "step=1200, a1 =  0.6942, a2 = 0.2099, b=-5.5957, loss = 0.1296\n",
      "step=1500, a1 =  0.5838, a2 = 0.5046, b=-6.3223, loss = 0.1086\n",
      "step=1800, a1 =  0.4853, a2 = 0.7623, b=-6.9408, loss = 0.0933\n",
      "step=2100, a1 =  0.3988, a2 = 0.9881, b=-7.4793, loss = 0.0816\n",
      "step=2400, a1 =  0.3229, a2 = 1.1872, b=-7.9563, loss = 0.0725\n",
      "step=2700, a1 =  0.2562, a2 = 1.3642, b=-8.3843, loss = 0.0652\n",
      "step=3000, a1 =  0.1973, a2 = 1.5226, b=-8.7725, loss = 0.0592\n",
      "공부한 시간: 7, 과외 수없 횟수: 6\n",
      "합격 가능성:  85.13 %\n"
     ]
    }
   ],
   "source": [
    "# 학습 \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(3001): \n",
    "        a_,b_,loss_, _ = sess.run([a,b,loss,gradient_decent], feed_dict={X: x_data, Y: y_data})\n",
    "        if (i + 1) % 300 == 0: \n",
    "            print(\"step=%d, a1 =  %.4f, a2 = %.4f, b=%.4f, loss = %.4f\" % (i + 1, a_[0], a_[1], b_, loss_))\n",
    "# 어떻게 활용한느가\n",
    "    new_x = np.array([7,6.]).reshape(1,2)\n",
    "#과외 수업 횟수 \n",
    "    new_y = sess.run(y, feed_dict ={X: new_x})\n",
    "    print(\"공부한 시간: %d, 과외 수없 횟수: %d\" % (new_x[: ,0], new_x[:,1]))\n",
    "    print(\"합격 가능성: %6.2f %%\" % (new_y * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
